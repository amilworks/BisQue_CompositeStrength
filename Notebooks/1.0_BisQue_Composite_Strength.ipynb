{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Composite Strength Prediction Function**\n",
    "### Version 1 | Amil Khan, Marat I. Latypov\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Import Packages**\n",
    "\n",
    "`PyMKS`\n",
    "- The Materials Knowledge Materials in Python (`PyMKS`) framework is an object-oriented set of tools and examples, written in `Python`, that provide high-level access to the MKS framework for rapid creation and analysis of structure-property-processing relationships. Check the package out if you have not already.\n",
    "\n",
    "- The __Materials Knowledge Systems (MKS)__ is a novel data science approach for solving multiscale materials science problems. It uses techniques from _physics, machine learning, regression analysis, signal processing, and spatial statistics to create processing-structure-property relationships_. The MKS carries the potential to bridge multiple length scales using localization and homogenization linkages, and provides a data driven framework for solving inverse material design problems.\n",
    "\n",
    "`H5PY`\n",
    "- Package to read HDF files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymks import PrimitiveBasis\n",
    "from pymks.stats import correlate\n",
    "from sklearn.externals import joblib\n",
    "import numpy as np\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Prediction Function**\n",
    "\n",
    "\n",
    "    Predicts effective strength of 3-D RVE of a 2-phase composite with strength contrast s2/s1 = 5\n",
    "    Args: \n",
    "    - table_path - path to dream3d file containing microstructure data (phase labels)\n",
    "    - predictor_path - path to sav file containing calibrated model (LinearRegression)\n",
    "    - reducer_path - path to sav file containing dimensionality reducer (Principal Component Basis)\n",
    "    - ms_path - path to microstructure data (phase lables) inside dream3d file\n",
    "    Returns:\n",
    "    - y - predicted effective strength \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(table_path,predictor_path,reducer_path,ms_path='/DataContainers/SyntheticVolumeDataContainer/CellData/Phases'):\n",
    "\n",
    "      \n",
    "    # Default settings for 2-pt stats\n",
    "    p_axes = (0,1,2)\n",
    "    corrs = [(1,1)]\n",
    "    \n",
    "    # Read hdf5 table\n",
    "    f = h5py.File(table_path, 'r')\n",
    "    data = f[ms_path].value\n",
    "    ms = np.squeeze(data)\n",
    "    print \"Table loaded successfully...\"\n",
    "    \n",
    "    # Get phase labels as local states\n",
    "    states = np.unique(ms)\n",
    "    if len(states) > 2 :\n",
    "        print('WARNING: Model is only for two-phase materials! All extra phases will be considered as the second (hard) phase')\n",
    "        ms[ms > states[0]] = states[0]   \n",
    "    \n",
    "    # Get the size of the RVE\n",
    "    if len(ms.shape) == 4:\n",
    "        dims = ms.shape[1:4]\n",
    "    elif len(ms.shape) == 3:\n",
    "        dims = ms.shape\n",
    "        ms = np.expand_dims(ms,0)\n",
    "    else:\n",
    "        print('ERROR: 3-D RVE(s) are expected!')\n",
    "        return None\n",
    "    \n",
    "    # Load model and dimensionality reducer\n",
    "    predictor = joblib.load(predictor_path)\n",
    "    reducer = joblib.load(reducer_path)\n",
    "    \n",
    "    # Get the number of PC components used\n",
    "    n_comps = predictor.named_steps['poly'].n_input_features_\n",
    "\n",
    "    # Get the size of the calibration RVE\n",
    "    nx_cal = int(np.round((reducer.components_.shape[1])**(1.0/3.0)))\n",
    "    dims_cal = np.array((nx_cal,nx_cal,nx_cal))\n",
    "    \n",
    "    # Compute 2-pt stats\n",
    "    n_states = len(states)\n",
    "    p_basis = PrimitiveBasis(n_states=n_states, domain=states)\n",
    "    tps = correlate(ms, p_basis, periodic_axes=p_axes, correlations=corrs)\n",
    "    \n",
    "    # Check size of the provided MVE: truncate if large, pad if small\n",
    "    if np.prod(dims) > reducer.components_.shape[1]:\n",
    "        tps = truncate(tps, [len(ms),dims_cal[0],dims_cal[1],dims_cal[2],1])\n",
    "        dims = dims_cal\n",
    "        print('Microstructure volume is larger than calibration RVE. 2-pt correlation function is truncated')\n",
    "    elif np.prod(dims) < reducer.components_.shape[1]:\n",
    "        tps = pad(tps, [len(ms),dims_cal[0],dims_cal[1],dims_cal[2],1])\n",
    "        dims = dims_cal\n",
    "        print('Microstructure volume is smaller than calibration RVE. 2-pt correlation function is padded')\n",
    "    \n",
    "    # Convert 2-pt stats to a vector\n",
    "    tps_v = np.reshape(tps,(len(ms), np.prod(dims)))\n",
    "\n",
    "    # Get low-dimensional representation\n",
    "    x = reducer.transform(tps_v)\n",
    "    \n",
    "    # Get the property prediction\n",
    "    y = predictor.predict(x[:,0:n_comps])\n",
    "    print \"Returning Results... \\n\"\n",
    "    return y\n",
    "\n",
    "def truncate(a, shape):\n",
    "    '''truncates the edges of the array based on the shape. '''\n",
    "    \n",
    "    a_shape = np.array(a.shape)\n",
    "    n = len(shape)\n",
    "    new_shape = a_shape.copy()\n",
    "    new_shape[:n] = shape\n",
    "    diff_shape = a_shape - new_shape\n",
    "    index0 = (diff_shape + (diff_shape % 2) * (new_shape % 2)) // 2\n",
    "    index1 = index0 + new_shape\n",
    "    multi_slice = tuple(slice(index0[ii], index1[ii]) for ii in range(n))\n",
    "    return a[multi_slice]\n",
    "\n",
    "def pad(a, shape):\n",
    "    '''pads the array with zeros to make for the shape'''\n",
    "    \n",
    "    a_shape = np.array(a.shape)\n",
    "    diff = shape-a_shape\n",
    "    pad_1 = (diff/2.0).astype(int)\n",
    "    pad_2 = diff - pad_1\n",
    "    \n",
    "    padding = []\n",
    "    for ii in range(len(pad_1)):\n",
    "        padding.append((pad_1[ii],pad_2[ii]))\n",
    "    \n",
    "    return np.pad(a,padding,'constant',constant_values=(0,0))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Does it Work?**\n",
    "There's only one way to find out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table loaded successfully...\n",
      "Returning Results... \n",
      "\n",
      "Predicted Strength:  0.466483628072\n"
     ]
    }
   ],
   "source": [
    "predictor_path = 'predictor.sav'\n",
    "reducer_path = 'reducer.sav'\n",
    "table_path = 'example_27x27x27.dream3d'\n",
    "\n",
    "\n",
    "y_hat = predict(table_path,predictor_path,reducer_path)\n",
    "print \"Predicted Strength: \", float(y_hat) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
